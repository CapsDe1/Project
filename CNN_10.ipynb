{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Flatten, Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# GPU 메모리 설정 코드 추가\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 352 epochs, Labels: 352\n",
      "Validation set size: 88 epochs, Labels: 88\n",
      "ADHD Training set size: 172 epochs\n",
      "Control Training set size: 180 epochs\n",
      "ADHD Validation set size: 48 epochs\n",
      "Control Validation set size: 40 epochs\n"
     ]
    }
   ],
   "source": [
    "# ADHD와 Control 데이터 경로\n",
    "adhd_epochs_path = r\"C:\\Users\\dlwld\\Desktop\\comprehensive_design\\DataSet Files\\ADHD_epochs_modify\"\n",
    "control_epochs_path = r\"C:\\Users\\dlwld\\Desktop\\comprehensive_design\\DataSet Files\\Control_epochs\"\n",
    "\n",
    "# 학습된 피험자 데이터가 검증 데이터로 들어가지 않도록 설정\n",
    "def load_epochs_by_subject(folder_path, label):\n",
    "    subject_epochs = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".npy\"):\n",
    "            # 피험자 ID 추출 (ex : 'v1p_epoch_1.npy'에서 'v1p' 추출)\n",
    "            subject_id = file_name.split('_')[0]\n",
    "            epoch_data = np.load(os.path.join(folder_path, file_name))\n",
    "            \n",
    "            if subject_id not in subject_epochs:\n",
    "                subject_epochs[subject_id] = []\n",
    "            \n",
    "            subject_epochs[subject_id].append((epoch_data, label))\n",
    "    return subject_epochs\n",
    "\n",
    "# ADHD와 Control 데이터 피험자별로 로드\n",
    "adhd_subject_epochs = load_epochs_by_subject(adhd_epochs_path, 1)  # ADHD label = 1\n",
    "control_subject_epochs = load_epochs_by_subject(control_epochs_path, 0)  # Control label = 0\n",
    "\n",
    "# 피험자 ID 목록 생성\n",
    "adhd_subjects = list(adhd_subject_epochs.keys())\n",
    "control_subjects = list(control_subject_epochs.keys())\n",
    "\n",
    "# 학습/검증 피험자 분리 (80% 학습, 20% 검증)\n",
    "adhd_train_subjects, adhd_test_subjects = train_test_split(adhd_subjects, test_size=0.2, random_state=42)\n",
    "control_train_subjects, control_test_subjects = train_test_split(control_subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "# 학습 데이터와 검증 데이터 생성 함수\n",
    "def create_dataset(subject_epochs, subjects):\n",
    "    X = []\n",
    "    y = []\n",
    "    for subject in subjects:\n",
    "        epochs = subject_epochs[subject]\n",
    "        for epoch_data, label in epochs:\n",
    "            X.append(epoch_data)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 학습 및 검증 데이터 생성\n",
    "X_train_adhd, y_train_adhd = create_dataset(adhd_subject_epochs, adhd_train_subjects)\n",
    "X_test_adhd, y_test_adhd = create_dataset(adhd_subject_epochs, adhd_test_subjects)\n",
    "X_train_control, y_train_control = create_dataset(control_subject_epochs, control_train_subjects)\n",
    "X_test_control, y_test_control = create_dataset(control_subject_epochs, control_test_subjects)\n",
    "\n",
    "# 학습 및 검증 데이터 결합\n",
    "X_train = np.concatenate([X_train_adhd, X_train_control], axis=0)\n",
    "y_train = np.concatenate([y_train_adhd, y_train_control], axis=0)\n",
    "X_test = np.concatenate([X_test_adhd, X_test_control], axis=0)\n",
    "y_test = np.concatenate([y_test_adhd, y_test_control], axis=0)\n",
    "\n",
    "# 데이터 형태 재정의\n",
    "X_train = X_train.reshape(X_train.shape[0], 19, 15360, 1)  # (에포크 수, 채널 수, 샘플 수, 필터 수)\n",
    "X_test = X_test.reshape(X_test.shape[0], 19, 15360, 1)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"Training set size: {X_train.shape[0]} epochs, Labels: {y_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_test.shape[0]} epochs, Labels: {y_test.shape[0]}\")\n",
    "\n",
    "# ADHD와 Control 각각의 학습 및 검증 데이터 크기\n",
    "print(f\"ADHD Training set size: {X_train_adhd.shape[0]} epochs\")\n",
    "print(f\"Control Training set size: {X_train_control.shape[0]} epochs\")\n",
    "print(f\"ADHD Validation set size: {X_test_adhd.shape[0]} epochs\")\n",
    "print(f\"Control Validation set size: {X_test_control.shape[0]} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 1/10\n",
      "3/3 [==============================] - 1s 185ms/step\n",
      "Training iteration 2/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 3/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 4/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 5/10\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001623E303D90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 95ms/step\n",
      "Training iteration 6/10\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001623E300280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 7/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 8/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 9/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "Training iteration 10/10\n",
      "3/3 [==============================] - 0s 96ms/step\n",
      "\n",
      "CNN Classification Results Over 10 Repeated Training Times\n",
      "Accuracy: 0.73 ± 0.05\n",
      "Precision ADHD: 0.72 ± 0.05\n",
      "Precision Control: 0.75 ± 0.07\n",
      "Recall ADHD: 0.83 ± 0.06\n",
      "Recall Control: 0.60 ± 0.09\n",
      "F1-score ADHD: 0.77 ± 0.04\n",
      "F1-score Control: 0.67 ± 0.07\n",
      "AUC: 0.79 ± 0.05\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표 저장 리스트\n",
    "accuracy_list = []\n",
    "precision_adhd_list = []\n",
    "precision_control_list = []\n",
    "recall_adhd_list = []\n",
    "recall_control_list = []\n",
    "f1_adhd_list = []\n",
    "f1_control_list = []\n",
    "auc_list = []\n",
    "\n",
    "# 반복 학습 횟수\n",
    "num_repeats = 10\n",
    "\n",
    "# CNN 모델 학습 및 평가 반복\n",
    "for i in range(num_repeats):\n",
    "    print(f\"Training iteration {i + 1}/{num_repeats}\")\n",
    "    \n",
    "    # CNN 모델 정의\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (10, 1), activation='relu', input_shape=(19, 15360, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(2, 1)))\n",
    "    model.add(Conv2D(16, (4, 1), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(2, 1)))\n",
    "    model.add(Conv2D(32, (1, 128), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(1, 64)))\n",
    "    model.add(Conv2D(32, (1, 64), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(1, 32)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일 및 학습\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.3, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # 모델 예측\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(acc)\n",
    "\n",
    "    # Precision\n",
    "    precision_adhd = precision_score(y_test, y_pred, pos_label=1)\n",
    "    precision_control = precision_score(y_test, y_pred, pos_label=0)\n",
    "    precision_adhd_list.append(precision_adhd)\n",
    "    precision_control_list.append(precision_control)\n",
    "\n",
    "    # Recall\n",
    "    recall_adhd = recall_score(y_test, y_pred, pos_label=1)\n",
    "    recall_control = recall_score(y_test, y_pred, pos_label=0)\n",
    "    recall_adhd_list.append(recall_adhd)\n",
    "    recall_control_list.append(recall_control)\n",
    "\n",
    "    # F1-score\n",
    "    f1_adhd = f1_score(y_test, y_pred, pos_label=1)\n",
    "    f1_control = f1_score(y_test, y_pred, pos_label=0)\n",
    "    f1_adhd_list.append(f1_adhd)\n",
    "    f1_control_list.append(f1_control)\n",
    "\n",
    "    # AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_probs)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# 평균 및 표준 편차 계산\n",
    "accuracy_mean = np.mean(accuracy_list)\n",
    "accuracy_std = np.std(accuracy_list)\n",
    "\n",
    "precision_adhd_mean = np.mean(precision_adhd_list)\n",
    "precision_adhd_std = np.std(precision_adhd_list)\n",
    "\n",
    "precision_control_mean = np.mean(precision_control_list)\n",
    "precision_control_std = np.std(precision_control_list)\n",
    "\n",
    "recall_adhd_mean = np.mean(recall_adhd_list)\n",
    "recall_adhd_std = np.std(recall_adhd_list)\n",
    "\n",
    "recall_control_mean = np.mean(recall_control_list)\n",
    "recall_control_std = np.std(recall_control_list)\n",
    "\n",
    "f1_adhd_mean = np.mean(f1_adhd_list)\n",
    "f1_adhd_std = np.std(f1_adhd_list)\n",
    "\n",
    "f1_control_mean = np.mean(f1_control_list)\n",
    "f1_control_std = np.std(f1_control_list)\n",
    "\n",
    "auc_mean = np.mean(auc_list)\n",
    "auc_std = np.std(auc_list)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nCNN Classification Results Over 10 Repeated Training Times\")\n",
    "print(f\"Accuracy: {accuracy_mean:.2f} ± {accuracy_std:.2f}\")\n",
    "print(f\"Precision ADHD: {precision_adhd_mean:.2f} ± {precision_adhd_std:.2f}\")\n",
    "print(f\"Precision Control: {precision_control_mean:.2f} ± {precision_control_std:.2f}\")\n",
    "print(f\"Recall ADHD: {recall_adhd_mean:.2f} ± {recall_adhd_std:.2f}\")\n",
    "print(f\"Recall Control: {recall_control_mean:.2f} ± {recall_control_std:.2f}\")\n",
    "print(f\"F1-score ADHD: {f1_adhd_mean:.2f} ± {f1_adhd_std:.2f}\")\n",
    "print(f\"F1-score Control: {f1_control_mean:.2f} ± {f1_control_std:.2f}\")\n",
    "print(f\"AUC: {auc_mean:.2f} ± {auc_std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 반복 1 ---\n",
      "Accuracy: 0.8295\n",
      "Precision ADHD: 0.8235\n",
      "Precision Control: 0.8378\n",
      "Recall ADHD: 0.8750\n",
      "Recall Control: 0.7750\n",
      "F1-score ADHD: 0.8485\n",
      "F1-score Control: 0.8052\n",
      "AUC: 0.8729\n",
      "\n",
      "--- 반복 2 ---\n",
      "Accuracy: 0.7045\n",
      "Precision ADHD: 0.6719\n",
      "Precision Control: 0.7917\n",
      "Recall ADHD: 0.8958\n",
      "Recall Control: 0.4750\n",
      "F1-score ADHD: 0.7679\n",
      "F1-score Control: 0.5938\n",
      "AUC: 0.8292\n",
      "\n",
      "--- 반복 3 ---\n",
      "Accuracy: 0.7273\n",
      "Precision ADHD: 0.7222\n",
      "Precision Control: 0.7353\n",
      "Recall ADHD: 0.8125\n",
      "Recall Control: 0.6250\n",
      "F1-score ADHD: 0.7647\n",
      "F1-score Control: 0.6757\n",
      "AUC: 0.7458\n",
      "\n",
      "--- 반복 4 ---\n",
      "Accuracy: 0.7045\n",
      "Precision ADHD: 0.6719\n",
      "Precision Control: 0.7917\n",
      "Recall ADHD: 0.8958\n",
      "Recall Control: 0.4750\n",
      "F1-score ADHD: 0.7679\n",
      "F1-score Control: 0.5938\n",
      "AUC: 0.7831\n",
      "\n",
      "--- 반복 5 ---\n",
      "Accuracy: 0.7500\n",
      "Precision ADHD: 0.7500\n",
      "Precision Control: 0.7500\n",
      "Recall ADHD: 0.8125\n",
      "Recall Control: 0.6750\n",
      "F1-score ADHD: 0.7800\n",
      "F1-score Control: 0.7105\n",
      "AUC: 0.8073\n",
      "\n",
      "--- 반복 6 ---\n",
      "Accuracy: 0.7614\n",
      "Precision ADHD: 0.7455\n",
      "Precision Control: 0.7879\n",
      "Recall ADHD: 0.8542\n",
      "Recall Control: 0.6500\n",
      "F1-score ADHD: 0.7961\n",
      "F1-score Control: 0.7123\n",
      "AUC: 0.7661\n",
      "\n",
      "--- 반복 7 ---\n",
      "Accuracy: 0.7159\n",
      "Precision ADHD: 0.7255\n",
      "Precision Control: 0.7027\n",
      "Recall ADHD: 0.7708\n",
      "Recall Control: 0.6500\n",
      "F1-score ADHD: 0.7475\n",
      "F1-score Control: 0.6753\n",
      "AUC: 0.8547\n",
      "\n",
      "--- 반복 8 ---\n",
      "Accuracy: 0.6705\n",
      "Precision ADHD: 0.6727\n",
      "Precision Control: 0.6667\n",
      "Recall ADHD: 0.7708\n",
      "Recall Control: 0.5500\n",
      "F1-score ADHD: 0.7184\n",
      "F1-score Control: 0.6027\n",
      "AUC: 0.7734\n",
      "\n",
      "--- 반복 9 ---\n",
      "Accuracy: 0.7727\n",
      "Precision ADHD: 0.7414\n",
      "Precision Control: 0.8333\n",
      "Recall ADHD: 0.8958\n",
      "Recall Control: 0.6250\n",
      "F1-score ADHD: 0.8113\n",
      "F1-score Control: 0.7143\n",
      "AUC: 0.7812\n",
      "\n",
      "--- 반복 10 ---\n",
      "Accuracy: 0.6364\n",
      "Precision ADHD: 0.6481\n",
      "Precision Control: 0.6176\n",
      "Recall ADHD: 0.7292\n",
      "Recall Control: 0.5250\n",
      "F1-score ADHD: 0.6863\n",
      "F1-score Control: 0.5676\n",
      "AUC: 0.7031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 반복 횟수 (리스트의 길이)\n",
    "num_repeats = len(accuracy_list)\n",
    "\n",
    "# 각 반복의 결과 출력\n",
    "for i in range(num_repeats):\n",
    "    print(f\"--- 반복 {i + 1} ---\")\n",
    "    print(f\"Accuracy: {accuracy_list[i]:.4f}\")\n",
    "    print(f\"Precision ADHD: {precision_adhd_list[i]:.4f}\")\n",
    "    print(f\"Precision Control: {precision_control_list[i]:.4f}\")\n",
    "    print(f\"Recall ADHD: {recall_adhd_list[i]:.4f}\")\n",
    "    print(f\"Recall Control: {recall_control_list[i]:.4f}\")\n",
    "    print(f\"F1-score ADHD: {f1_adhd_list[i]:.4f}\")\n",
    "    print(f\"F1-score Control: {f1_control_list[i]:.4f}\")\n",
    "    print(f\"AUC: {auc_list[i]:.4f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
